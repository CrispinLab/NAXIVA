{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NAXIVA Analysis - Dynamic Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, roc_curve, auc, precision_recall_curve, auc\n",
    "from sklearn.model_selection import LeaveOneOut, GridSearchCV\n",
    "\n",
    "import warnings\n",
    "from warnings import filterwarnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dynamic model (all baseline features + Wk3/Wk1 growth factor fold changes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_data = pd.read_csv('NAXIVA_data/NAXIVA_baseline_data.csv', index_col=0)\n",
    "dynamic_data = pd.read_csv('NAXIVA_data/NAXIVA_dynamic_data.csv', index_col=0)\n",
    "\n",
    "mod2_data = pd.merge(baseline_data, dynamic_data, left_index=True, right_index=True)\n",
    "\n",
    "\n",
    "responders = pd.read_csv('NAXIVA_data/NAXIVA_response_labels.csv')\n",
    "\n",
    "\n",
    "# Impute the missing patient data\n",
    "imputer = IterativeImputer(random_state = 42, keep_empty_features = False)\n",
    "mod2_imputed = imputer.fit_transform(mod2_data)\n",
    "mod2_data_imputed = pd.DataFrame(mod2_imputed, columns = mod2_data.columns, index = mod2_data.index)\n",
    "# mod2_data_imputed.replace(to_replace = 0, value = 1, inplace = True)\n",
    "\n",
    "# Scale the data using Min-Max scaling\n",
    "sc = MinMaxScaler((0, 1)) \n",
    "mod2_data_norm = sc.fit_transform(mod2_data_imputed)\n",
    "mod2_data_scaled = pd.DataFrame(mod2_data_norm, columns = mod2_data_imputed.columns, index = mod2_data_imputed.index)\n",
    "mod2_data_final = mod2_data_scaled\n",
    "\n",
    "# mod2_data_final.to_csv('data/mod2_data_final.csv')\n",
    "\n",
    "# Curate list of responders and replace words with numbers\n",
    "responders = responders.replace([\"non-responder\", \"stopped_early\", \"responder\"], [0, 0, 1])\n",
    "responders.set_index('trial_id', inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_correlated_features(df, threshold):\n",
    "    corr_matrix = df.corr(method='spearman').abs() # create correlation matrix of absolute correlation coefficient\n",
    "    iters = range(len(corr_matrix.columns) - 1) # calculate how many iterations are needed\n",
    "    drop_cols = []\n",
    "\n",
    "    # Iterate through the correlation matrix and compare correlations\n",
    "    for i in iters:\n",
    "        for j in range(i+1):\n",
    "            item = corr_matrix.iloc[j:(j+1), (i+1):(i+2)] # iterate over upper triangle of the correlation matrix\n",
    "            col = item.columns\n",
    "            row = item.index\n",
    "            val = abs(item.values)\n",
    "\n",
    "            # If correlation exceeds the threshold\n",
    "            if val >= threshold:\n",
    "                print(col.values[0], \"|\", row.values[0], \"|\", round(val[0][0], 2)) # Print the correlated features and the correlation value\n",
    "                drop_cols.append(col.values[0])\n",
    "\n",
    "    # Drop one of each pair of correlated columns\n",
    "    drops = set(drop_cols)\n",
    "    print(df.shape)\n",
    "    print(f'Columns dropped: {drops}')\n",
    "    print(f'N of columns dropped: {len(drops)}')\n",
    "    df = df.drop(columns=drops)\n",
    "    print(df.shape)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CCL2 baseline | IL-8 baseline | 0.88\n",
      "VEGF-C baseline | CCL13 baseline | 0.83\n",
      "CD34+ area baseline | CD31+ area baseline | 0.94\n",
      "CD31+ CD34+ area baseline | CD31+ area baseline | 0.96\n",
      "CD31+ CD34+ area baseline | CD34+ area baseline | 0.98\n",
      "CD8+ PD-1+ baseline | GZMB+ baseline | 0.83\n",
      "CD8+ GZMB- PD-1+ baseline | CD8+ baseline | 0.82\n",
      "CD8+ GZMB- PD-1+ baseline | CD8+ PD-1+ baseline | 0.97\n",
      "CD8+ GZMB+ PD-1+ baseline | GZMB+ baseline | 0.91\n",
      "CD8+ GZMB+ PD-1+ baseline | CD8+ PD-1+ baseline | 0.88\n",
      "CD8+ GZMB+ PD-1+ baseline | CD8+ GZMB- PD-1+ baseline | 0.82\n",
      "FOXP3+ baseline | CD4+ baseline | 0.86\n",
      "PD-1+ baseline | CD4+ baseline | 0.91\n",
      "PD-1+ baseline | FOXP3+ baseline | 0.91\n",
      "Treg baseline | CD4+ baseline | 0.9\n",
      "Treg baseline | FOXP3+ baseline | 0.97\n",
      "Treg baseline | PD-1+ baseline | 0.95\n",
      "Treg PD-1+ baseline | CD4+ baseline | 0.91\n",
      "Treg PD-1+ baseline | FOXP3+ baseline | 0.9\n",
      "Treg PD-1+ baseline | PD-1+ baseline | 0.95\n",
      "Treg PD-1+ baseline | Treg baseline | 0.94\n",
      "Treg PD-1- baseline | CD4+ baseline | 0.85\n",
      "Treg PD-1- baseline | FOXP3+ baseline | 0.96\n",
      "Treg PD-1- baseline | PD-1+ baseline | 0.89\n",
      "Treg PD-1- baseline | Treg baseline | 0.96\n",
      "Treg PD-1- baseline | Treg PD-1+ baseline | 0.87\n",
      "CD4+ PD-1+ baseline | CD4+ baseline | 0.92\n",
      "CD4+ PD-1+ baseline | FOXP3+ baseline | 0.87\n",
      "CD4+ PD-1+ baseline | PD-1+ baseline | 0.98\n",
      "CD4+ PD-1+ baseline | Treg baseline | 0.92\n",
      "CD4+ PD-1+ baseline | Treg PD-1+ baseline | 0.96\n",
      "CD4+ PD-1+ baseline | Treg PD-1- baseline | 0.84\n",
      "CD4+ PD-1- baseline | CD4+ baseline | 0.98\n",
      "CD4+ PD-1- baseline | FOXP3+ baseline | 0.8\n",
      "CD4+ PD-1- baseline | PD-1+ baseline | 0.83\n",
      "CD4+ PD-1- baseline | Treg baseline | 0.84\n",
      "CD4+ PD-1- baseline | Treg PD-1+ baseline | 0.84\n",
      "CD4+ PD-1- baseline | Treg PD-1- baseline | 0.77\n",
      "CD4+ PD-1- baseline | CD4+ PD-1+ baseline | 0.85\n",
      "CD8+ of CD3+ baseline | CD4+ of CD3+ baseline | 0.9\n",
      "CD4+/CD8+ ratio baseline | CD4+ of CD3+ baseline | 0.95\n",
      "CD4+/CD8+ ratio baseline | CD8+ of CD3+ baseline | 0.92\n",
      "CD4+ Tem baseline | CD4+ naïve baseline | 0.85\n",
      "CD8+ effector baseline | CD4+ of CD3+ baseline | 0.75\n",
      "CD8+ effector baseline | CD8+ of CD3+ baseline | 0.8\n",
      "CD8 Tem baseline | CD8+ of CD3+ baseline | 0.78\n",
      "(20, 69)\n",
      "Columns dropped: {'CD8+ of CD3+ baseline', 'CD34+ area baseline', 'CD4+/CD8+ ratio baseline', 'CD4+ Tem baseline', 'VEGF-C baseline', 'CD4+ PD-1- baseline', 'Treg baseline', 'CD31+ CD34+ area baseline', 'CD8+ GZMB- PD-1+ baseline', 'CD8 Tem baseline', 'Treg PD-1+ baseline', 'FOXP3+ baseline', 'CD8+ effector baseline', 'CD4+ PD-1+ baseline', 'CD8+ GZMB+ PD-1+ baseline', 'Treg PD-1- baseline', 'PD-1+ baseline', 'CCL2 baseline', 'CD8+ PD-1+ baseline'}\n",
      "N of columns dropped: 19\n",
      "(20, 50)\n",
      "Features remaining: ['IFN-g baseline', 'IL-10 baseline', 'IL-12p70 baseline', 'IL-6 baseline', 'IL-8 baseline', 'TNF-a baseline', 'Eotaxin baseline', 'Eotaxin-3 baseline', 'CXCL10 baseline', 'CCL13 baseline', 'CCL22 baseline', 'CCL3 baseline', 'CCL4 baseline', 'CCL17 baseline', 'IL-1a baseline', 'IL-12/23 baseline', 'IL-15 baseline', 'IL-16 baseline', 'IL-17a baseline', 'IL-7 baseline', 'LTa baseline', 'FGF baseline', 'sVEGFR-1 baseline', 'PlGF baseline', 'Tie-2 baseline', 'VEGF-A baseline', 'VEGF-D baseline', 'Necrosis baseline', 'CD31+ area baseline', 'CD68+ baseline', 'SMA+ area baseline', 'Ki67+ nuclei baseline', 'CD8+ baseline', 'GZMB+ baseline', 'CD8+ GZMB+ PD-1- baseline', 'CD8+ GZMB- PD-1- baseline', 'CD4+ baseline', 'CD4+ of CD3+ baseline', 'CD4+ effector baseline', 'CD4+ naïve baseline', 'CD4+ Tcm baseline', 'CD8+ naïve baseline', 'CD8+ Tcm baseline', 'FGF_fold_change_week_3', 'sVEGFR-1_fold_change_week_3', 'PlGF_fold_change_week_3', 'Tie-2_fold_change_week_3', 'VEGF-A_fold_change_week_3', 'VEGF-C_fold_change_week_3', 'VEGF-D_fold_change_week_3']\n"
     ]
    }
   ],
   "source": [
    "# Define threshold\n",
    "threshold = 0.75\n",
    "# Remove highly correlated features from database\n",
    "mod2_data_final = remove_correlated_features(mod2_data_final, threshold)\n",
    "print(f'Features remaining: {list(mod2_data_final.columns)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Leave one-out supervised learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod2_methods = {\n",
    "    'Logistic Regression RFE 3': RFE(estimator = LogisticRegression(), n_features_to_select=3, step=1),\n",
    "}\n",
    "\n",
    "# Choose supervised learning methods\n",
    "mod2_algorithms = {\n",
    "    \"Logistic SGD\" : (SGDClassifier(loss = 'log_loss', class_weight='balanced', max_iter=1000), {\n",
    "        'alpha': [0.0001, 0.001, 0.01, 0.1, 1, 10, 100],\n",
    "        'penalty': ['l1', 'l2', 'elasticnet'],\n",
    "        'learning_rate': ['optimal', 'invscaling', 'adaptive'],\n",
    "        'eta0': [0.01, 0.1, 1],\n",
    "    }),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression RFE 3\n",
      "Logistic SGD\n",
      "Patients: 20\n",
      "Predictions: 20\n",
      "Iterations: 20\n",
      "AUC: 0.945054945054945\n",
      "Youden's index: 0.49739721924428687\n"
     ]
    }
   ],
   "source": [
    "# Make multi-index data frame to save results\n",
    "mod2_method_names = list(mod2_methods.keys())\n",
    "mod2_alg_names = list(mod2_algorithms.keys())\n",
    "iterations = range(20)\n",
    "mod2_index = pd.MultiIndex.from_product([mod2_methods, mod2_algorithms, iterations], names=['Method', 'Algorithm', 'Iteration'])\n",
    "mod2_results = pd.DataFrame(index=mod2_index, columns=['trial_id', 'hyperparams', 'selected_features', 'coef', 'auc', 'accuracy', 'sensitivity', 'precision', 'f1-score', 'auprc', 'scores'])\n",
    "\n",
    "# Generate empty series for outputs: prediction and score\n",
    "y_true = responders['responder']\n",
    "y_pred = pd.Series(index = y_true.index)\n",
    "y_score = pd.Series(index = y_true.index)\n",
    "\n",
    "# Create a series called y_train_pred for each training set in the leave-one-out cross-validation\n",
    "y_train_pred = pd.DataFrame(index = mod2_index, columns=responders.index)\n",
    "mod2_results = pd.merge(mod2_results, y_train_pred, left_index=True, right_index=True, how = 'inner')\n",
    "\n",
    "random.seed(10)\n",
    "np.random.seed(10)\n",
    "\n",
    "for method_name in mod2_methods: # For each method in the pre-formed list of methods\n",
    "    method = mod2_methods[method_name]\n",
    "\n",
    "    for alg_name, (alg, param_grid_2) in mod2_algorithms.items(): # Within each method, loop over all the algorithms in the pre-formed list of algorithms\n",
    "\n",
    "        random.seed(10)\n",
    "        np.random.seed(10)\n",
    "\n",
    "        # Generate leave-one-out index lists\n",
    "        loo = LeaveOneOut() \n",
    "        for i, (train_idx, test_idx) in enumerate(loo.split(y_true)): # Create lists of indices which leaves one patient out with each iteration\n",
    "            y_train = y_true[train_idx]\n",
    "            y_test = y_true[test_idx]\n",
    "            X_train = mod2_data_final.loc[list(y_train.index)]\n",
    "            X_test = mod2_data_final.loc[list(y_test.index)]\n",
    "\n",
    "            # Apply feature selection algorithm for each leave-one-out iteration\n",
    "            data = method.fit(X_train, y_train)\n",
    "            mask = method.get_support(indices = True)\n",
    "            selected_features = list(X_train.iloc[:, mask])\n",
    "\n",
    "            mod2_results.at[(method_name, alg_name, i), 'selected_features'] = (selected_features) # Save feature names to dataframe               \n",
    "\n",
    "            # Apply only selected features from the cytokine dataset for each leave-one-out iteration\n",
    "            X_train = X_train[selected_features]\n",
    "            X_test = X_test[selected_features]\n",
    "\n",
    "            # Hyperparameter tuning\n",
    "            selected_hyperparameters_2 = []\n",
    "            grid_search = GridSearchCV(alg, param_grid = param_grid_2, cv = 5, scoring = 'roc_auc') # Param grid is specified earlier for each algorithm\n",
    "            grid_search.fit(X_train, y_train)\n",
    "            best_params = grid_search.best_params_\n",
    "            selected_hyperparameters_2 = best_params # Save selected hyperparameters for each split\n",
    "            alg.set_params(**best_params) # Set best hyperparameters for algorithm    \n",
    "\n",
    "            # Train and predict\n",
    "            alg.fit(X_train, y_train)  # Fit the algorithm on the training set\n",
    "\n",
    "            # Save coefficients for logistic regression\n",
    "            coef_dict = {}\n",
    "            for feature, coef in zip(alg.feature_names_in_, alg.coef_[0]):\n",
    "                coef_dict[feature] = coef\n",
    "            mod2_results.loc[(method_name, alg_name, i), 'coef'] = [(coef_dict)] # Save selected features coefficients\n",
    "\n",
    "            # Save predicted label to y_pred series\n",
    "            y_pred[list(y_test.index)] = alg.predict(X_test) \n",
    "            y_score[list(y_test.index)] = alg.predict_proba(X_test)[:, 1]\n",
    "            mod2_results.at[(method_name, alg_name, i), 'trial_id'] = y_test.index[0]\n",
    "            mod2_results.at[(method_name, alg_name, i), 'scores'] = alg.predict_proba(X_test)[:,1]\n",
    "            \n",
    "            for j, k in enumerate(X_train.index):\n",
    "                mod2_results.at[(method_name, alg_name, i), k] = alg.predict_proba(X_train)[:,1][j]\n",
    "\n",
    "            mod2_results.loc[(method_name, alg_name, i), 'hyperparams'] = [selected_hyperparameters_2.copy()] # Save selected hyperparameters\n",
    "\n",
    "        precision, recall, thresholds = precision_recall_curve(y_true, y_score)\n",
    "        auprc = auc(recall, precision)\n",
    "\n",
    "        mod2_results.loc[(method_name, alg_name, 0), 'auc'] = roc_auc_score(y_true, y_score) # Save AUC ROC score\n",
    "        mod2_results.loc[(method_name, alg_name, 0), 'accuracy'] = accuracy_score(y_true, y_pred) # Save accuracy score\n",
    "        mod2_results.loc[(method_name, alg_name, 0), 'sensitivity'] = recall_score(y_true, y_pred) # Save sensitivity score\n",
    "        mod2_results.loc[(method_name, alg_name, 0), 'precision'] = precision_score(y_true, y_pred) # Save precision score\n",
    "        mod2_results.loc[(method_name, alg_name, 0), 'f1-score'] = f1_score(y_true, y_pred) # Save f1-score\n",
    "        mod2_results.loc[(method_name, alg_name, 0), 'auprc'] = auc(recall, precision) # Save AUC PRC score\n",
    "        # mod2_results.loc[(method_name, alg_name, 0), 'scores'] = [y_score.copy()] # Save scores\n",
    "        \n",
    "        # Check LOOCV \n",
    "        print(method_name)\n",
    "        print(alg_name)\n",
    "        print(f'Patients: {len(list(y_true.index))}')\n",
    "        print(f'Predictions: {len(list(y_pred.index))}')\n",
    "        print(f'Iterations: {i+1}')\n",
    "        print(f'AUC: {roc_auc_score(y_true, y_score)}')\n",
    "        assert len(list(y_true.index)) == len(list(y_pred.index)), 'True and predicted labels have different lengths'\n",
    "\n",
    "\n",
    "mod2_results.to_csv(f\"dynamic_model_results.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
